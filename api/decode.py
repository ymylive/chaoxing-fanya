# -*- coding: utf-8 -*-
"""
è¶…æ˜Ÿå­¦ä¹ é€šæ•°æ®è§£ææ¨¡å—

è¯¥æ¨¡å—è´Ÿè´£è§£æè¶…æ˜Ÿå­¦ä¹ é€šå¹³å°çš„è¯¾ç¨‹ã€ç« èŠ‚ã€ä»»åŠ¡ç‚¹ç­‰å„ç§æ•°æ®ï¼Œ
å¹¶è½¬æ¢ä¸ºç¨‹åºå†…éƒ¨ä½¿ç”¨çš„ç»“æ„åŒ–æ•°æ®æ ¼å¼ã€‚
"""
import json
import re
import os
import sys
import tempfile
import threading
import io
from typing import List, Dict, Tuple, Any, Optional, Union

from bs4 import BeautifulSoup, NavigableString

from api.font_decoder import FontDecoder
from api.logger import logger
from api.config import GlobalConst as gc
from api.cookies import use_cookies
from api.vision_ocr import vision_ocr, is_vision_ocr_enabled
import requests

try:
    from PIL import Image, ImageEnhance, ImageFilter
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

ENABLE_LOCAL_OCR = os.environ.get("CHAOXING_ENABLE_OCR", "0").strip().lower() in {"1", "true", "yes", "y", "on"}
_PADDLE_OCR_ENGINE = None
_PADDLE_OCR_INITIALIZED = False
_PADDLE_OCR_DEVICE = None  # è®°å½•å½“å‰ OCR å¼•æ“è¿è¡Œçš„è®¾å¤‡ï¼ˆgpu / cpuï¼‰
_PADDLE_OCR_LOCK = threading.RLock()


def _init_paddle_ocr(preferred_device: Optional[str] = None):
    """å»¶è¿Ÿåˆå§‹åŒ– PaddleOCR å¼•æ“ã€‚

    - ä¼˜å…ˆä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ PaddleOCR ä»“åº“ï¼ˆå…‹éš†åçš„ä»£ç ï¼‰ï¼›
    - å¤±è´¥æ—¶è®°å½•æ—¥å¿—å¹¶è¿”å› Noneï¼Œä¸å½±å“ä¸»æµç¨‹ã€‚
    """
    global _PADDLE_OCR_ENGINE, _PADDLE_OCR_INITIALIZED, _PADDLE_OCR_DEVICE

    with _PADDLE_OCR_LOCK:
        if preferred_device and preferred_device != _PADDLE_OCR_DEVICE:
            # å¼ºåˆ¶åˆ‡æ¢è®¾å¤‡æ—¶éœ€è¦é‡æ–°åˆå§‹åŒ–
            _PADDLE_OCR_INITIALIZED = False
            _PADDLE_OCR_ENGINE = None

        if _PADDLE_OCR_INITIALIZED and _PADDLE_OCR_ENGINE is not None:
            return _PADDLE_OCR_ENGINE

        _PADDLE_OCR_INITIALIZED = True
        try:
            project_root = os.path.dirname(os.path.dirname(__file__))
            paddle_root = os.path.join(project_root, "PaddleOCR")
            if os.path.isdir(paddle_root) and paddle_root not in sys.path:
                sys.path.append(paddle_root)

            from paddleocr import PaddleOCR  # type: ignore

            devices_to_try: List[str] = []
            if preferred_device:
                devices_to_try.append(preferred_device)
                if preferred_device != "cpu":
                    devices_to_try.append("cpu")
            else:
                devices_to_try = ["gpu", "cpu"]

            last_exc: Optional[Exception] = None
            for device in devices_to_try:
                try:
                    # ä¼˜åŒ–å‚æ•°ä»¥æé«˜å…¬å¼/æ–‡å­—è¯†åˆ«ç‡ï¼š
                    # - det_db_thresh: é™ä½æ£€æµ‹é˜ˆå€¼ï¼Œæ›´å®¹æ˜“æ£€æµ‹åˆ°æµ…è‰²æ–‡å­—
                    # - det_db_box_thresh: é™ä½æ¡†æ£€æµ‹é˜ˆå€¼ï¼Œä¿ç•™æ›´å¤šå€™é€‰åŒºåŸŸ
                    # - det_db_unclip_ratio: å¢å¤§æ–‡æœ¬æ¡†æ‰©å±•æ¯”ä¾‹ï¼Œé¿å…è£åˆ‡è¾¹ç¼˜
                    # - use_angle_cls: å¯ç”¨æ–¹å‘åˆ†ç±»ï¼Œå¤„ç†å€¾æ–œæ–‡å­—
                    engine = PaddleOCR(
                        lang="ch",
                        device=device,
                        det_db_thresh=0.2,
                        det_db_box_thresh=0.4,
                        det_db_unclip_ratio=1.8,
                        use_angle_cls=True,
                    )
                    _PADDLE_OCR_ENGINE = engine
                    _PADDLE_OCR_DEVICE = device
                    logger.info(f"PaddleOCR åˆå§‹åŒ–æˆåŠŸ ({device.upper()})ï¼Œå°†ç”¨äºé¢˜ç›®å›¾ç‰‡ OCR")
                    return _PADDLE_OCR_ENGINE
                except Exception as exc_device:
                    last_exc = exc_device
                    logger.warning(f"PaddleOCR {device.upper()} åˆå§‹åŒ–å¤±è´¥: {exc_device}")

            if last_exc:
                raise last_exc
        except Exception as exc:
            cause = getattr(exc, "__cause__", None)
            if cause is not None:
                logger.warning(
                    f"PaddleOCR åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨æœ¬åœ° OCR: {exc} (åº•å±‚ä¾èµ–é”™è¯¯: {cause})"
                )
            else:
                logger.warning(f"PaddleOCR åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä¸ä½¿ç”¨æœ¬åœ° OCR: {exc}")
            _PADDLE_OCR_ENGINE = None
            _PADDLE_OCR_DEVICE = None

        return _PADDLE_OCR_ENGINE


def _preprocess_image_for_ocr(image_bytes: bytes, enhance_mode: int = 0) -> bytes:
    """é¢„å¤„ç†å›¾ç‰‡ä»¥æé«˜ OCR è¯†åˆ«ç‡ã€‚
    
    enhance_mode:
        0 - æ ‡å‡†é¢„å¤„ç†ï¼šè°ƒæ•´å¤§å°ã€å¢å¼ºå¯¹æ¯”åº¦
        1 - é«˜å¯¹æ¯”åº¦æ¨¡å¼ï¼šæ›´å¼ºçš„å¯¹æ¯”åº¦å¢å¼º + é”åŒ–
        2 - äºŒå€¼åŒ–æ¨¡å¼ï¼šè½¬ç°åº¦åè¿›è¡Œé˜ˆå€¼å¤„ç†
    
    è¿”å›å¤„ç†åçš„ PNG å›¾ç‰‡å­—èŠ‚æ•°æ®ã€‚
    """
    if not PIL_AVAILABLE:
        return image_bytes
    
    try:
        img = Image.open(io.BytesIO(image_bytes))
        
        # è½¬æ¢ä¸º RGBï¼ˆå¤„ç† RGBA æˆ–å…¶ä»–æ¨¡å¼ï¼‰
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            if img.mode == 'P':
                img = img.convert('RGBA')
            background.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')
        
        # å¦‚æœå›¾ç‰‡å¤ªå°ï¼Œæ”¾å¤§ä»¥æé«˜è¯†åˆ«ç‡
        min_dimension = 100
        width, height = img.size
        if width < min_dimension or height < min_dimension:
            scale = max(min_dimension / width, min_dimension / height, 2.0)
            new_size = (int(width * scale), int(height * scale))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œç¼©å°ä»¥åŠ å¿«å¤„ç†é€Ÿåº¦
        max_dimension = 2000
        width, height = img.size
        if width > max_dimension or height > max_dimension:
            scale = min(max_dimension / width, max_dimension / height)
            new_size = (int(width * scale), int(height * scale))
            img = img.resize(new_size, Image.Resampling.LANCZOS)
        
        if enhance_mode == 0:
            # æ ‡å‡†æ¨¡å¼ï¼šè½»å¾®å¢å¼ºå¯¹æ¯”åº¦å’Œé”åº¦
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(1.3)
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.2)
        elif enhance_mode == 1:
            # é«˜å¯¹æ¯”åº¦æ¨¡å¼
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(1.8)
            enhancer = ImageEnhance.Sharpness(img)
            img = enhancer.enhance(1.5)
            # è½»å¾®å»å™ª
            img = img.filter(ImageFilter.MedianFilter(size=3))
        elif enhance_mode == 2:
            # äºŒå€¼åŒ–æ¨¡å¼ï¼šè½¬ç°åº¦ï¼Œå¢å¼ºå¯¹æ¯”åº¦ï¼Œç„¶åç”¨é˜ˆå€¼å¤„ç†
            img = img.convert('L')
            enhancer = ImageEnhance.Contrast(img)
            img = enhancer.enhance(2.0)
            # ç®€å•é˜ˆå€¼äºŒå€¼åŒ–
            threshold = 180
            img = img.point(lambda p: 255 if p > threshold else 0)
            img = img.convert('RGB')
        
        # è¾“å‡ºä¸º PNG
        output = io.BytesIO()
        img.save(output, format='PNG')
        return output.getvalue()
    except Exception as exc:
        logger.debug(f"å›¾ç‰‡é¢„å¤„ç†å¤±è´¥: {exc}")
        return image_bytes


def _call_http_ocr(ocr_endpoint: str, image_bytes: bytes, img_url: str) -> str:
    """è°ƒç”¨ HTTP OCR æœåŠ¡"""
    try:
        files = {"file": ("question.png", image_bytes, "image/png")}
        ocr_resp = requests.post(ocr_endpoint, files=files, timeout=20)
        if ocr_resp.status_code != 200:
            logger.debug(f"HTTP OCR æœåŠ¡è¿”å›å¼‚å¸¸çŠ¶æ€ç : {ocr_resp.status_code}")
            return ""
        data = ocr_resp.json()
    except Exception as exc:
        logger.debug(f"è°ƒç”¨ HTTP OCR æœåŠ¡å¤±è´¥: {exc}")
        return ""

    # å°è¯•ä»å¸¸è§å­—æ®µä¸­è¯»å– LaTeX/æ–‡æœ¬ç»“æœ
    for key in ("latex", "text", "result", "data"):
        value = data.get(key)
        if isinstance(value, str) and value.strip():
            logger.debug(f"HTTP OCR è¯†åˆ«æˆåŠŸ: {value[:100]}... æ¥è‡ª {img_url}")
            return value.strip()

    return ""


def _ocr_image_to_text(img_url: str) -> str:
    """å¯é€‰çš„ OCR é’©å­ï¼šå°†é¢˜å¹²ä¸­çš„å›¾ç‰‡è½¬ä¸ºæ¥è¿‘ LaTeX çš„æ–‡æœ¬ã€‚

    OCR è¯†åˆ«é€»è¾‘ï¼š
    - è‹¥é…ç½®äº†å¤–éƒ¨ AI è§†è§‰æ¨¡å‹ï¼ˆCHAOXING_VISION_OCR_PROVIDER + KEYï¼‰ï¼Œåˆ™ä½¿ç”¨å¤–éƒ¨ OCRï¼Œè·³è¿‡æœ¬åœ°
    - è‹¥æœªé…ç½®å¤–éƒ¨ OCRï¼Œåˆ™å°è¯•æœ¬åœ° PaddleOCRï¼ˆéœ€è¦ CHAOXING_ENABLE_OCR=1ï¼‰
    - æœ€åå¯é€‰ HTTP OCR æœåŠ¡ä½œä¸ºå…œåº•ï¼ˆCHAOXING_OCR_ENDPOINTï¼‰

    åœ¨æœªå¼€å¯ä»»ä½• OCR æ—¶ï¼Œæœ¬å‡½æ•°ç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œä¸å½±å“åŸæœ‰é€»è¾‘ã€‚
    """
    if not img_url:
        return ""

    # åˆ¤æ–­æ˜¯å¦é…ç½®äº†å¤–éƒ¨ AI è§†è§‰ OCR
    use_external_ocr = is_vision_ocr_enabled()

    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½• OCR æ–¹å¼å¯ç”¨
    has_any_ocr = (
        use_external_ocr
        or ENABLE_LOCAL_OCR
        or os.environ.get("CHAOXING_OCR_ENDPOINT", "").strip()
    )
    if not has_any_ocr:
        return ""

    # ä¸‹è½½å›¾ç‰‡
    try:
        # ä½¿ç”¨å¸¦ç™»å½• Cookie çš„ä¼šè¯ä¸‹è½½å›¾ç‰‡ï¼Œé¿å… 403
        session = requests.Session()
        session.headers.update(gc.HEADERS)
        session.cookies.update(use_cookies())

        # å¯¹è¶…æ˜Ÿå›¾ç‰‡åŸŸåè¡¥å……ä¸€ä¸ªç®€å• Refererï¼Œè¿›ä¸€æ­¥é™ä½ 403 æ¦‚ç‡
        extra_headers = {}
        if "p.ananas.chaoxing.com" in img_url:
            extra_headers["Referer"] = "https://mooc1.chaoxing.com/"

        resp = session.get(img_url, headers=extra_headers or None, timeout=8)
        if resp.status_code != 200:
            logger.debug(f"ä¸‹è½½é¢˜ç›®å›¾ç‰‡å¤±è´¥: {img_url} -> {resp.status_code}")
            return ""
        image_bytes = resp.content
    except Exception as exc:
        logger.debug(f"ä¸‹è½½é¢˜ç›®å›¾ç‰‡å¼‚å¸¸: {exc}")
        return ""

    # 1) è‹¥é…ç½®äº†å¤–éƒ¨ AI è§†è§‰ OCRï¼Œä¼˜å…ˆä½¿ç”¨ï¼Œè·³è¿‡æœ¬åœ° OCR
    if use_external_ocr:
        try:
            vision_result = vision_ocr(image_bytes)
            if vision_result:
                logger.debug(f"å¤–éƒ¨ AI è§†è§‰ OCR è¯†åˆ«æˆåŠŸ: {vision_result[:100]}... æ¥è‡ª {img_url}")
                return vision_result
            else:
                logger.debug(f"å¤–éƒ¨ AI è§†è§‰ OCR æœªè¯†åˆ«å‡ºæ–‡æœ¬ æ¥è‡ª {img_url}")
        except Exception as exc:
            logger.debug(f"å¤–éƒ¨ AI è§†è§‰ OCR è°ƒç”¨å¤±è´¥: {exc}")
        # å¤–éƒ¨ OCR å¤±è´¥æ—¶ï¼Œä¸å›é€€åˆ°æœ¬åœ°ï¼Œç›´æ¥å°è¯• HTTP OCR æˆ–è¿”å›ç©º
        ocr_endpoint = os.environ.get("CHAOXING_OCR_ENDPOINT", "").strip()
        if ocr_endpoint:
            return _call_http_ocr(ocr_endpoint, image_bytes, img_url)
        return ""

    # 2) æœªé…ç½®å¤–éƒ¨ OCR æ—¶ï¼Œä½¿ç”¨æœ¬åœ° PaddleOCR
    if ENABLE_LOCAL_OCR:
        engine = _init_paddle_ocr()
    else:
        engine = None

    if engine is not None:
        tmp_path = None
        try:
            # å°è¯•å¤šç§é¢„å¤„ç†æ¨¡å¼ï¼Œç›´åˆ°è·å¾—æœ‰æ•ˆæ–‡æœ¬
            # æ¨¡å¼ 0: æ ‡å‡†é¢„å¤„ç†ï¼ˆå¯¹æ¯”åº¦+é”åŒ–ï¼‰
            # æ¨¡å¼ 1: é«˜å¯¹æ¯”åº¦æ¨¡å¼
            # æ¨¡å¼ 2: äºŒå€¼åŒ–æ¨¡å¼
            preprocessing_modes = [0, 1, 2]
            
            def _parse_ocr_result(ocr_result) -> List[str]:
                """è§£æ OCR ç»“æœï¼Œè¿”å›è¯†åˆ«çš„æ–‡æœ¬åˆ—è¡¨"""
                parsed_texts: List[str] = []
                if not ocr_result:
                    return parsed_texts
                try:
                    if isinstance(ocr_result, list) and ocr_result and isinstance(ocr_result[0], dict):
                        # æ–°ç»“æ„ï¼šlist[dict]ï¼Œæ¯ä¸ª dict å†…åŒ…å« rec_texts / rec_scores ç­‰å­—æ®µ
                        for page in ocr_result:
                            if not isinstance(page, dict):
                                continue
                            rec_texts = page.get("rec_texts") or []
                            for t in rec_texts:
                                if isinstance(t, str) and t.strip():
                                    parsed_texts.append(t.strip())
                    else:
                        # æ—§ç»“æ„ï¼šç±»ä¼¼ [[box, (text, score)], ...]
                        for page in ocr_result:
                            for line in page:
                                if len(line) >= 2 and isinstance(line[1], (list, tuple)):
                                    text = line[1][0]
                                    if isinstance(text, str) and text.strip():
                                        parsed_texts.append(text.strip())
                except Exception:
                    # æœ€åçš„å›é€€ï¼šç›´æ¥æŠŠç»“æœè½¬æˆå­—ç¬¦ä¸²
                    result_str = str(ocr_result).strip()
                    if result_str and result_str not in ('[]', 'None', '[[]]'):
                        parsed_texts.append(result_str)
                return parsed_texts
            
            final_texts: List[str] = []
            for preprocess_mode in preprocessing_modes:
                # é¢„å¤„ç†å›¾ç‰‡
                processed_bytes = _preprocess_image_for_ocr(image_bytes, enhance_mode=preprocess_mode)
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶
                if tmp_path:
                    try:
                        os.remove(tmp_path)
                    except OSError:
                        pass
                fd, tmp_path = tempfile.mkstemp(suffix=".png")
                with os.fdopen(fd, "wb") as f:
                    f.write(processed_bytes)
                
                # æ‰§è¡Œ OCR
                for device_attempt in range(2):
                    try:
                        with _PADDLE_OCR_LOCK:
                            ocr_result = engine.ocr(tmp_path)
                        final_texts = _parse_ocr_result(ocr_result)
                        break
                    except Exception as exc:
                        global _PADDLE_OCR_DEVICE
                        if device_attempt == 0 and _PADDLE_OCR_DEVICE == "gpu":
                            logger.debug(f"PaddleOCR GPU æ¨ç†å¤±è´¥ï¼Œåˆ‡æ¢åˆ° CPU: {exc}")
                            engine = _init_paddle_ocr(preferred_device="cpu")
                            if engine is None:
                                break
                            continue
                        logger.debug(f"PaddleOCR è¯†åˆ«å¤±è´¥ (æ¨¡å¼{preprocess_mode}): {exc}")
                        break
                
                if final_texts:
                    logger.debug(
                        f"PaddleOCR æå–æ–‡æœ¬æˆåŠŸ (é¢„å¤„ç†æ¨¡å¼{preprocess_mode}): {' '.join(final_texts)} æ¥è‡ª {img_url}"
                    )
                    break
                else:
                    logger.debug(f"PaddleOCR é¢„å¤„ç†æ¨¡å¼{preprocess_mode}æœªè¯†åˆ«å‡ºæ–‡æœ¬ï¼Œå°è¯•ä¸‹ä¸€æ¨¡å¼")
            
            if not final_texts:
                logger.debug(f"PaddleOCR æ‰€æœ‰é¢„å¤„ç†æ¨¡å¼å‡æœªè¯†åˆ«å‡ºæ–‡æœ¬ æ¥è‡ª {img_url}")
            
            if final_texts:
                # å°†å¤šè¡Œç»“æœåˆå¹¶ä¸ºä¸€è¡Œï¼Œäº¤ç»™å¤§æ¨¡å‹è¿›ä¸€æ­¥ç†è§£
                return " ".join(final_texts)
        finally:
            if tmp_path:
                try:
                    os.remove(tmp_path)
                except OSError:
                    pass

    # 3) è‹¥é…ç½®äº† HTTP OCR æœåŠ¡ï¼Œåˆ™ä½œä¸ºæœ€åå…œåº•
    ocr_endpoint = os.environ.get("CHAOXING_OCR_ENDPOINT", "").strip()
    if ocr_endpoint:
        return _call_http_ocr(ocr_endpoint, image_bytes, img_url)

    return ""


def _normalize_bool(value: Union[str, bool, int, float]) -> bool:
    """ç»Ÿä¸€è½¬æ¢å¸ƒå°”å€¼ï¼Œé¿å…å­—ç¬¦ä¸² 'false' è¢«å½“æˆ True ç­‰é—®é¢˜"""
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return value != 0
    if isinstance(value, str):
        return value.strip().lower() in {"true", "1", "yes", "y", "passed"}
    return False


def decode_course_list(html_text: str) -> List[Dict[str, str]]:
    """
    è§£æè¯¾ç¨‹åˆ—è¡¨é¡µé¢ï¼Œæå–è¯¾ç¨‹ä¿¡æ¯
    
    Args:
        html_text: è¯¾ç¨‹åˆ—è¡¨é¡µé¢çš„HTMLå†…å®¹
        
    Returns:
        è¯¾ç¨‹ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªè¯¾ç¨‹åŒ…å«idã€titleã€teacherç­‰ä¿¡æ¯
    """
    logger.trace("å¼€å§‹è§£ç è¯¾ç¨‹åˆ—è¡¨...")
    soup = BeautifulSoup(html_text, "lxml")
    raw_courses = soup.select("div.course")
    course_list = []
    
    for course in raw_courses:
        # è·³è¿‡æœªå¼€æ”¾è¯¾ç¨‹
        if course.select_one("a.not-open-tip") or course.select_one("div.not-open-tip"):
            continue
        
        course_detail = {
            "id": course.attrs["id"],
            "info": course.attrs["info"],
            "roleid": course.attrs["roleid"],
            "clazzId": course.select_one("input.clazzId").attrs["value"],
            "courseId": course.select_one("input.courseId").attrs["value"],
            "cpi": re.findall(r"cpi=(.*?)&", course.select_one("a").attrs["href"])[0],
            "title": course.select_one("span.course-name").attrs["title"],
            "desc": course.select_one("p.margint10").attrs["title"] if course.select_one("p.margint10") else "",
            "teacher": course.select_one("p.color3").attrs["title"]
        }
        course_list.append(course_detail)
    
    return course_list


def decode_course_folder(html_text: str) -> List[Dict[str, str]]:
    """
    è§£æäºŒçº§è¯¾ç¨‹åˆ—è¡¨é¡µé¢ï¼Œæå–æ–‡ä»¶å¤¹ä¿¡æ¯
    
    Args:
        html_text: äºŒçº§è¯¾ç¨‹åˆ—è¡¨é¡µé¢çš„HTMLå†…å®¹
        
    Returns:
        è¯¾ç¨‹æ–‡ä»¶å¤¹ä¿¡æ¯åˆ—è¡¨
    """
    logger.trace("å¼€å§‹è§£ç äºŒçº§è¯¾ç¨‹åˆ—è¡¨...")
    soup = BeautifulSoup(html_text, "lxml")
    raw_courses = soup.select("ul.file-list>li")
    course_folder_list = []
    
    for course in raw_courses:
        if not course.attrs.get("fileid"):
            continue
            
        course_folder_detail = {
            "id": course.attrs["fileid"],
            "rename": course.select_one("input.rename-input").attrs["value"]
        }
        course_folder_list.append(course_folder_detail)
    
    return course_folder_list


def decode_course_point(html_text: str) -> Dict[str, Any]:
    """
    è§£æç« èŠ‚åˆ—è¡¨é¡µé¢ï¼Œæå–ç« èŠ‚ç‚¹ä¿¡æ¯
    
    Args:
        html_text: ç« èŠ‚åˆ—è¡¨é¡µé¢çš„HTMLå†…å®¹
        
    Returns:
        ç« èŠ‚ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«æ˜¯å¦é”å®šçŠ¶æ€å’Œç« èŠ‚ç‚¹åˆ—è¡¨
    """
    logger.trace("å¼€å§‹è§£ç ç« èŠ‚åˆ—è¡¨...")
    soup = BeautifulSoup(html_text, "lxml")
    course_point = {
        "hasLocked": False,  # ç”¨äºåˆ¤æ–­è¯¥è¯¾ç¨‹ä»»åŠ¡æ˜¯å¦æ˜¯éœ€è¦è§£é”
        "points": [],
    }

    for chapter_unit in soup.find_all("div", class_="chapter_unit"):
        points = _extract_points_from_chapter(chapter_unit)
        # æ£€æŸ¥æ˜¯å¦æœ‰é”å®šå†…å®¹
        for point in points:
            if point.get("need_unlock", False):
                course_point["hasLocked"] = True
                
        course_point["points"].extend(points)
    
    return course_point


def _extract_points_from_chapter(chapter_unit) -> List[Dict[str, Any]]:
    """
    ä»ç« èŠ‚å•å…ƒä¸­æå–ç« èŠ‚ç‚¹ä¿¡æ¯
    
    Args:
        chapter_unit: BeautifulSoupå¯¹è±¡ï¼Œè¡¨ç¤ºä¸€ä¸ªç« èŠ‚å•å…ƒ
        
    Returns:
        ç« èŠ‚ç‚¹ä¿¡æ¯åˆ—è¡¨
    """
    point_list = []
    raw_points = chapter_unit.find_all("li")
    
    for raw_point in raw_points:
        point = raw_point.div
        if "id" not in point.attrs:
            continue
            
        point_id = re.findall(r"^cur(\d{1,20})$", point.attrs["id"])[0]
        point_title = point.select_one("a.clicktitle").text.replace("\n", "").strip()
        
        # æå–ä»»åŠ¡æ•°é‡
        job_count = 1  # é»˜è®¤ä¸º1
        need_unlock = False
        if point.select_one("input.knowledgeJobCount"):
            job_count = point.select_one("input.knowledgeJobCount").attrs["value"]
        elif point.select_one("span.bntHoverTips") and "è§£é”" in point.select_one("span.bntHoverTips").text:
            need_unlock = True
            
        # åˆ¤æ–­æ˜¯å¦å·²å®Œæˆ
        is_finished = False
        if point.select_one("span.bntHoverTips") and "å·²å®Œæˆ" in point.select_one("span.bntHoverTips").text:
            is_finished = True
            
        point_detail = {
            "id": point_id,
            "title": point_title,
            "jobCount": job_count,
            "has_finished": is_finished,
            "need_unlock": need_unlock
        }
        point_list.append(point_detail)
        
    return point_list


def decode_course_card(html_text: str) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    è§£æä»»åŠ¡ç‚¹åˆ—è¡¨é¡µé¢ï¼Œæå–ä»»åŠ¡ç‚¹ä¿¡æ¯
    
    Args:
        html_text: ä»»åŠ¡ç‚¹åˆ—è¡¨é¡µé¢çš„HTMLå†…å®¹
        
    Returns:
        ä»»åŠ¡ç‚¹åˆ—è¡¨å’Œä»»åŠ¡ä¿¡æ¯çš„å…ƒç»„
    """
    logger.trace("å¼€å§‹è§£ç ä»»åŠ¡ç‚¹åˆ—è¡¨...")
    
    # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœªå¼€æ”¾
    if "ç« èŠ‚æœªå¼€æ”¾" in html_text:
        return [], {"notOpen": True}

    # æå–mArgå‚æ•°
    temp = re.findall(r"mArg=\{(.*?)\};", html_text.replace(" ", ""))
    if not temp:
        return [], {}

    # è§£æJSONæ•°æ®
    cards_data = json.loads("{" + temp[0] + "}")

    if not cards_data:
        return [], {}

    # æå–ä»»åŠ¡ä¿¡æ¯
    job_info = _extract_job_info(cards_data)

    # å¤„ç†æ‰€æœ‰é™„ä»¶ä»»åŠ¡
    cards = cards_data.get("attachments", [])
    job_list = _process_attachment_cards(cards)

    return job_list, job_info


def _extract_job_info(cards_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ä»å¡ç‰‡æ•°æ®ä¸­æå–ä»»åŠ¡åŸºæœ¬ä¿¡æ¯
    
    Args:
        cards_data: å¡ç‰‡æ•°æ®å­—å…¸
        
    Returns:
        ä»»åŠ¡åŸºæœ¬ä¿¡æ¯å­—å…¸
    """
    defaults = cards_data.get("defaults", {})
    if not defaults:
        return {}
        
    return {
        "ktoken": defaults.get("ktoken", ""),
        "mtEnc": defaults.get("mtEnc", ""),
        "reportTimeInterval": defaults.get("reportTimeInterval", 60),
        "defenc": defaults.get("defenc", ""),
        "cardid": defaults.get("cardid", ""),
        "cpi": defaults.get("cpi", ""),
        "qnenc": defaults.get("qnenc", ""),
        "knowledgeid": defaults.get("knowledgeid", "")
    }


def _process_attachment_cards(cards: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    å¤„ç†æ‰€æœ‰é™„ä»¶ä»»åŠ¡å¡ç‰‡ï¼Œå¼ºåŒ–ç›´æ’­ä»»åŠ¡è¯†åˆ«é€»è¾‘
    
    Args:
        cards: é™„ä»¶ä»»åŠ¡å¡ç‰‡åˆ—è¡¨
        
    Returns:
        å¤„ç†åçš„ä»»åŠ¡åˆ—è¡¨
    """
    job_list = []
    
    for index, card in enumerate(cards):
        # è·³è¿‡å·²é€šè¿‡çš„ä»»åŠ¡ï¼ˆå­—ç¬¦ä¸²/æ•°å­—ä¹Ÿèƒ½æ­£ç¡®è¯†åˆ«ï¼‰
        card_passed = _normalize_bool(card.get("isPassed", False))
        card["isPassed"] = card_passed
        if card_passed:
            continue

        # å¤„ç†æ— jobå­—æ®µçš„ç‰¹æ®Šä»»åŠ¡
        if card.get("job") is None:
            # å°è¯•è¯†åˆ«é˜…è¯»ä»»åŠ¡
            read_job = _process_read_task(card)
            if read_job:
                job_list.append(read_job)
            continue

        # ä¸€å¼€å§‹å°±æŠŠè¶…æ˜Ÿapiçš„å±å±±å¤„ç†æ‰ï¼Œä¸è¦ç”¨ä¸€ä¸ªå±å±±è¡Œä¸ºæ©ç›–å¦ä¸€ä¸ªå±å±± (æŒ‡æ ¹æ®otherInfoä¸­æ˜¯å¦æœ‰courseIdå†³å®šurlæ‹¼æ¥æ–¹å¼ğŸ˜‚)
        # æ¸…ç†otherInfoå­—æ®µä¸­çš„æ— æ•ˆå‚æ•°ï¼Œè¿™é‡Œä¼˜åŒ–äº†ä¸€ä¸‹(ä¿ç•™äº†ä½œè€…åŸæ¥çš„æ³¨é‡ŠTATï¼‰
        if "otherInfo" in card:
            logger.trace("Fixing other info...")
            card["otherInfo"] = card["otherInfo"].split("&")[0]
            logger.trace(f"New info: {card['otherInfo']}")

        # å¤šç»´åº¦åˆ¤æ–­æ˜¯å¦ä¸ºç›´æ’­ä»»åŠ¡
        card_type = card.get("type", "").lower()
        property_data = card.get("property", {})
        prop_type = property_data.get("type", "").lower()
        resource_type = property_data.get("resourceType", "").lower()
        
        # ç›´æ’­ä»»åŠ¡ç‰¹å¾ï¼šåŒ…å«liveIdã€streamNameç­‰å­—æ®µï¼Œ
        # æˆ–ç±»å‹æ ‡è¯†åŒ…å«liveï¼ˆå› ä¸ºliveå’Œvideoæœ‰ç‚¹ç±»ä¼¼ï¼Œæ€•è¶…æ˜Ÿåˆæå‡ºä»€ä¹ˆå¹ºè›¾å­å°±åŠ äº†ä¸€äº›å…³é”®å­—è¯†åˆ«ï¼‰
        is_live = (
            "live" in card_type 
            or "live" in prop_type
            or "live" in resource_type
            or "livestream" in card_type
            or property_data.get("liveId") is not None
            or property_data.get("streamName") is not None
            or property_data.get("vdoid") is not None
        )

        # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†
        if is_live:
            live_job = _process_live_task(card)
            if live_job:
                job_list.append(live_job)
        elif card_type == "video":
            video_job = _process_video_task(card)
            if video_job:
                job_list.append(video_job)
        elif card_type == "document":
            doc_job = _process_document_task(card)
            if doc_job:
                job_list.append(doc_job)
        elif card_type == "workid":
            work_job = _process_work_task(card)
            if work_job:
                job_list.append(work_job)
        else:
            logger.warning(f"Unknown card type: {card_type}")
            logger.warning(card)

    return job_list


def _process_live_task(card: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """å¤„ç†ç›´æ’­ç±»å‹ä»»åŠ¡ï¼Œæå–æ‰€æœ‰å¿…è¦å‚æ•°"""
    try:
        property_data = card.get("property", {})
        return {
            "type": "live",
            "jobid": card.get("jobid", str(card.get("id", ""))),  # å…¼å®¹ä¸åŒæ ¼å¼çš„ä»»åŠ¡ID
            "name": property_data.get("title", property_data.get("name", "æœªçŸ¥ç›´æ’­")),
            "otherinfo": card.get("otherInfo", ""),
            "property": property_data,  # ä¿ç•™å®Œæ•´å±æ€§ç”¨äºåç»­å¤„ç†
            "mid": card.get("mid", ""),
            "objectid": card.get("objectId", ""),
            "aid": card.get("aid", ""),
            # è¡¥å……ç›´æ’­ç‰¹æœ‰æ ‡è¯†
            "liveId": property_data.get("liveId"),
            "streamName": property_data.get("streamName")
        }
    except Exception as e:
        logger.error(f"è§£æç›´æ’­ä»»åŠ¡å¤±è´¥: {str(e)}, ä»»åŠ¡æ•°æ®: {str(card)[:200]}")
        return None
def _process_read_task(card: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """å¤„ç†é˜…è¯»ç±»å‹ä»»åŠ¡"""
    read_flag = _normalize_bool(card.get("property", {}).get("read", False))
    if not (card.get("type") == "read" and not read_flag):
        return None
        
    return {
        "title": card.get("property", {}).get("title", ""),
        "type": "read",
        "id": card.get("property", {}).get("id", ""),
        "jobid": card.get("jobid", ""),
        "jtoken": card.get("jtoken", ""),
        "mid": card.get("mid", ""),
        "otherinfo": card.get("otherInfo", ""),
        "enc": card.get("enc", ""),
        "aid": card.get("aid", "")
    }


def _process_video_task(card: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """å¤„ç†è§†é¢‘ç±»å‹ä»»åŠ¡"""
    try:
        return {
            "type": "video",
            "jobid": card.get("jobid", ""),
            "name": card.get("property", {}).get("name", ""),
            "otherinfo": card.get("otherInfo", ""),
            "mid": card["mid"],  # å¿…é¡»å­—æ®µï¼Œå¦‚æœä¸å­˜åœ¨ä¼šæŠ›å‡ºå¼‚å¸¸
            "objectid": card.get("objectId", ""),
            "aid": card.get("aid", ""),
            "playTime": card.get("playTime", 0),
            "rt": card.get("property", {}).get("rt", ""),
            "attDuration": card.get("attDuration", ""),
            "attDurationEnc": card.get("attDurationEnc", ""),
            "videoFaceCaptureEnc": card.get("videoFaceCaptureEnc", ""),
        }
    except KeyError:
        logger.warning("å‡ºç°è½¬ç å¤±è´¥è§†é¢‘ï¼Œå·²è·³è¿‡...")
        return None


def _process_document_task(card: Dict[str, Any]) -> Dict[str, Any]:
    """å¤„ç†æ–‡æ¡£ç±»å‹ä»»åŠ¡"""
    return {
        "type": "document",
        "jobid": card.get("jobid", ""),
        "otherinfo": card.get("otherInfo", ""),
        "jtoken": card.get("jtoken", ""),
        "mid": card.get("mid", ""),
        "enc": card.get("enc", ""),
        "aid": card.get("aid", ""),
        "objectid": card.get("property", {}).get("objectid", "")
    }


def _process_work_task(card: Dict[str, Any]) -> Dict[str, Any]:
    """å¤„ç†ä½œä¸šç±»å‹ä»»åŠ¡"""
    return {
        "type": "workid",
        "jobid": card.get("jobid", ""),
        "otherinfo": card.get("otherInfo", ""),
        "mid": card.get("mid", ""),
        "enc": card.get("enc", ""),
        "aid": card.get("aid", "")
    }


def decode_questions_info(html_content: str) -> Dict[str, Any]:
    """
    è§£æé¢˜ç›®ä¿¡æ¯ï¼Œæå–è¡¨å•æ•°æ®å’Œé—®é¢˜åˆ—è¡¨
    
    Args:
        html_content: é¢˜ç›®é¡µé¢HTMLå†…å®¹
        
    Returns:
        åŒ…å«è¡¨å•æ•°æ®å’Œé—®é¢˜åˆ—è¡¨çš„å­—å…¸
    """
    soup = BeautifulSoup(html_content, "lxml")
    form_data = _extract_form_data(soup)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å­—ä½“åŠ å¯†
    has_font_encryption = bool(soup.find("style", id="cxSecretStyle"))
    font_decoder = None
    
    if has_font_encryption:
        font_decoder = FontDecoder(html_content)
    else:
        logger.warning("æœªæ‰¾åˆ°å­—ä½“æ–‡ä»¶ï¼Œå¯èƒ½æ˜¯æœªåŠ å¯†çš„é¢˜ç›®ä¸è¿›è¡Œè§£å¯†")
    
    # å¤„ç†æ‰€æœ‰é—®é¢˜
    questions = []
    for div_tag in soup.find("form").find_all("div", class_="singleQuesId"):
        question = _process_question(div_tag, font_decoder)
        if question:
            questions.append(question)
    
    # æ›´æ–°è¡¨å•æ•°æ®
    form_data["questions"] = questions
    form_data["answerwqbid"] = ",".join([q["id"] for q in questions]) + ","
    
    return form_data


def _extract_form_data(soup: BeautifulSoup) -> Dict[str, Any]:
    """ä»BeautifulSoupå¯¹è±¡ä¸­æå–è¡¨å•æ•°æ®"""
    form_data = {}
    form_tag = soup.find("form")
    
    if not form_tag:
        return form_data
    
    # æå–æ‰€æœ‰éç­”æ¡ˆå­—æ®µçš„input
    for input_tag in form_tag.find_all("input"):
        if "name" not in input_tag.attrs or "answer" in input_tag.attrs["name"]:
            continue
        form_data[input_tag.attrs["name"]] = input_tag.attrs.get("value", "")
    
    return form_data


def _process_question(div_tag, font_decoder=None) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªé—®é¢˜"""
    # æå–é—®é¢˜IDå’Œé¢˜ç›®ç±»å‹
    question_id = div_tag.attrs.get("data", "")
    q_type_code = div_tag.find("div", class_="TiMu").attrs.get("data", "")
    q_type = _get_question_type(q_type_code)
    
    # æå–é¢˜ç›®å†…å®¹å’Œé€‰é¡¹
    title_div = div_tag.find("div", class_="Zy_TItle")
    options_list = div_tag.find("ul").find_all("li") if div_tag.find("ul") else []
    
    # è§£æé¢˜ç›®å’Œé€‰é¡¹
    q_title = _extract_title(title_div, font_decoder)
    q_options = []
    for li in options_list:
        q_options.append(_extract_choices(li, font_decoder))
    # æ’åºé€‰é¡¹
    q_options.sort()
    q_options = '\n'.join(q_options)
    
    # åˆå§‹åŒ–ç­”é¢˜å­—æ®µï¼šè‡³å°‘åŒ…å« answer{id} å’Œ answertype{id}
    answer_field: Dict[str, Any] = {
        f"answer{question_id}": "",
        f"answertype{question_id}": q_type_code,
    }

    # å…¼å®¹å¡«ç©ºé¢˜ç­‰å¯èƒ½å­˜åœ¨çš„å¤šä¸ª answer* å­—æ®µï¼ˆä¾‹å¦‚ answer{id}_0 ç­‰ï¼‰ï¼š
    # æ”¶é›†å½“å‰é¢˜ç›® div ä¸‹æ‰€æœ‰ name ä¸­åŒ…å« "answer" ä¸”ä¸æœ¬é¢˜ç›¸å…³çš„ input å­—æ®µåï¼Œ
    # ä»¥ä¾¿åç»­æŒ‰ç…§åŸå§‹å­—æ®µåå›å¡«ç­”æ¡ˆã€‚
    for input_tag in div_tag.find_all("input"):
        name = input_tag.attrs.get("name", "")
        if not name or "answer" not in name:
            continue
        # ä»…ä¿ç•™ä¸å½“å‰é¢˜ç›® ID ç›¸å…³çš„å­—æ®µï¼Œé¿å…æ±¡æŸ“å…¶ä»–é¢˜ç›®çš„å­—æ®µ
        if question_id and question_id not in name:
            continue
        if name not in answer_field:
            answer_field[name] = input_tag.attrs.get("value", "")

    return {
        "id": question_id,
        "title": q_title,
        "options": q_options,
        "type": q_type,
        "answerField": answer_field,
    }


def _get_question_type(type_code: str) -> str:
    """æ ¹æ®é¢˜å‹ä»£ç è¿”å›é¢˜å‹åç§°"""
    type_map = {
        "0": "single",      # å•é€‰é¢˜
        "1": "multiple",    # å¤šé€‰é¢˜
        "2": "completion",  # å¡«ç©ºé¢˜
        "3": "judgement",   # åˆ¤æ–­é¢˜
        "4": "shortanswer", # ç®€ç­”é¢˜
    }
    
    if type_code in type_map:
        return type_map[type_code]
    
    logger.info(f"æœªçŸ¥é¢˜å‹ä»£ç  -> {type_code}")
    return "unknown"


def _extract_title(element, font_decoder=None) -> str:
    """æå–æ ‡é¢˜å†…å®¹ï¼Œæ”¯æŒè§£ç åŠ å¯†å­—ä½“"""
    if not element:
        return ""
        
    # æ”¶é›†å…ƒç´ ä¸­çš„æ‰€æœ‰æ–‡æœ¬å’Œå›¾ç‰‡
    content = []
    for item in element.descendants:
        if isinstance(item, NavigableString):
            content.append(item.string or "")
        elif item.name == "img":
            img_url = item.get("src", "")
            # å¦‚æœå¯ç”¨äº†æœ¬åœ° OCRï¼Œåˆ™å°è¯•å°†å›¾ç‰‡è½¬æ¢ä¸ºæ¥è¿‘ LaTeX çš„æ–‡æœ¬è¡¨è¾¾
            ocr_text = _ocr_image_to_text(img_url)
            if ocr_text:
                content.append(f"[å…¬å¼: {ocr_text}]")
            else:
                content.append(f'<img src="{img_url}">')

    raw_content = "".join(content)
    cleaned_content = raw_content.replace("\r", "").replace("\t", "").replace("\n", "")
    
    # å¦‚æœæœ‰å­—ä½“è§£ç å™¨ï¼Œè¿›è¡Œè§£ç 
    if font_decoder:
        return font_decoder.decode(cleaned_content)
    
    return cleaned_content

def _extract_choices(element, font_decoder=None) -> str:
    """æå–é€‰é¡¹å†…å®¹ï¼Œæ”¯æŒè§£ç åŠ å¯†å­—ä½“"""
    if not element:
        return ""
        
    # æå–aria-labelå±æ€§å€¼ä½œä¸ºé€‰é¡¹ï¼Œè§£å†³#474
    choice = element.get("aria-label") or element.get_text()
    if not choice:
        return ""

    cleaned_content = re.sub(r"[\r\t\n]", "", choice)

    if font_decoder:
        cleaned_content = font_decoder.decode(cleaned_content)

    cleaned_content = cleaned_content.strip()
    if cleaned_content.endswith("é€‰æ‹©"):
        cleaned_content = cleaned_content[:-2].rstrip()

    return cleaned_content
